{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pond.tensor import NativeTensor, PrivateEncodedTensor, PublicEncodedTensor\n",
    "from pond.nn import Dense, Sigmoid, Reveal, Diff, Softmax, CrossEntropy, Sequential, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = dataset\n",
    "    \n",
    "    # NOTE: this is the shape used by Tensorflow; other backends may differ\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    x_train  = x_train.astype('float32')\n",
    "    x_test   = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test  /= 255\n",
    "\n",
    "    y_train = to_categorical(y_train, 5)\n",
    "    y_test  = to_categorical(y_test, 5)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train_public = x_train[y_train < 5]\n",
    "    y_train_public = y_train[y_train < 5]\n",
    "    x_test_public  = x_test[y_test < 5]\n",
    "    y_test_public  = y_test[y_test < 5]\n",
    "    public_dataset = (x_train_public, y_train_public), (x_test_public, y_test_public)\n",
    "\n",
    "    x_train_private = x_train[y_train >= 5]\n",
    "    y_train_private = y_train[y_train >= 5] - 5\n",
    "    x_test_private  = x_test[y_test >= 5]\n",
    "    y_test_private  = y_test[y_test >= 5] - 5\n",
    "    private_dataset = (x_train_private, y_train_private), (x_test_private, y_test_private)\n",
    "    \n",
    "    return preprocess_data(public_dataset), preprocess_data(private_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train on public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_dataset, private_dataset = load_data()\n",
    "\n",
    "feature_layers = [\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    keras.layers.Activation('sigmoid'),\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
    "    keras.layers.Activation('sigmoid'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Dropout(.25),\n",
    "    keras.layers.Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.Activation('sigmoid'),\n",
    "    keras.layers.Dropout(.50),\n",
    "    keras.layers.Dense(5),\n",
    "    keras.layers.Activation('softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(feature_layers + classification_layers)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = public_dataset\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from private data (unencrypted for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = model.get_layer(index=7)\n",
    "assert flatten_layer.name.startswith('flatten_')\n",
    "\n",
    "extractor = keras.models.Model(\n",
    "    inputs=model.input, \n",
    "    outputs=flatten_layer.output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_images, y_train), (x_test_images, y_test) = private_dataset\n",
    "\n",
    "x_train_features = extractor.predict(x_train_images)\n",
    "x_test_features  = extractor.predict(x_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train_features.npy', x_train_features)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('x_test_features.npy', x_test_features)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29404, 6272) (29404, 5) (4861, 6272) (4861, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train_features = np.load('x_train_features.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "x_test_features = np.load('x_test_features.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "print(x_train_features.shape, y_train.shape, x_test_features.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential([\n",
    "    Dense(128, 6272),\n",
    "    Sigmoid(),\n",
    "    # Dropout(.5),\n",
    "    Dense(5, 128),\n",
    "    Reveal(),\n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classifier, x, y, verbose=0, wrapper=NativeTensor):\n",
    "    predicted_classes = classifier \\\n",
    "        .predict(DataLoader(x, wrapper), verbose=verbose).reveal() \\\n",
    "        .argmax(axis=1)\n",
    "        \n",
    "    correct_classes = NativeTensor(y) \\\n",
    "        .argmax(axis=1)\n",
    "        \n",
    "    matches = predicted_classes.unwrap() == correct_classes.unwrap()\n",
    "    return sum(matches)/len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... using NativeTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-29 11:02:50.827373 Epoch 0\n",
      "2017-12-29 11:03:07.306861 Epoch 1\n",
      "2017-12-29 11:03:22.950060 Epoch 2\n",
      "Elapsed: 0:00:48.221433\n"
     ]
    }
   ],
   "source": [
    "classifier.initialize()\n",
    "\n",
    "start = datetime.now()\n",
    "classifier.fit(\n",
    "    DataLoader(x_train_features, wrapper=NativeTensor), \n",
    "    DataLoader(y_train, wrapper=NativeTensor), \n",
    "    loss=CrossEntropy(), \n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ")\n",
    "stop = datetime.now()\n",
    "\n",
    "print(\"Elapsed:\", stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.90671337233\n",
      "Test accuracy: 0.908660769389\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", accuracy(classifier, x_train_features, y_train))\n",
    "print(\"Test accuracy:\",  accuracy(classifier, x_test_features,  y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... using PublicEncodedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.initialize()\n",
    "\n",
    "start = datetime.now()\n",
    "classifier.fit(\n",
    "    DataLoader(x_train_features, wrapper=PublicEncodedTensor), \n",
    "    DataLoader(y_train, wrapper=PublicEncodedTensor),\n",
    "    loss=CrossEntropy(), \n",
    "    epochs=3,\n",
    "    verbose=2\n",
    ")\n",
    "stop = datetime.now()\n",
    "\n",
    "print(\"Elapsed:\", stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", accuracy(classifier, x_train_features, y_train, verbose=2))\n",
    "print(\"Test accuracy:\",  accuracy(classifier, x_test_features,  y_test,  verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... using PrivateEncodedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-29 11:03:42.926628 Epoch 0\n",
      "2017-12-29 11:03:43.243759 Batch 0\n",
      "2017-12-29 11:04:54.253005 Batch 1\n",
      "2017-12-29 11:06:37.272832 Batch 2\n",
      "2017-12-29 11:08:20.516759 Batch 3\n",
      "2017-12-29 11:09:56.260065 Batch 4\n",
      "2017-12-29 11:11:30.663451 Batch 5\n",
      "2017-12-29 11:13:04.473740 Batch 6\n",
      "2017-12-29 11:14:39.077599 Batch 7\n"
     ]
    }
   ],
   "source": [
    "classifier.initialize()\n",
    "\n",
    "start = datetime.now()\n",
    "classifier.fit(\n",
    "    DataLoader(x_train_features, wrapper=PrivateEncodedTensor), \n",
    "    DataLoader(y_train, wrapper=PrivateEncodedTensor),\n",
    "    loss=CrossEntropy(), \n",
    "    epochs=3,\n",
    "    verbose=2\n",
    ")\n",
    "stop = datetime.now()\n",
    "\n",
    "print(\"Elapsed:\", stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-02 14:13:39.032988 Batch 0\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy(classifier, x_train_features, y_train, verbose=2)\n",
    "test_accuracy  = accuracy(classifier, x_test_features,  y_test,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.906611345395\n",
      "Test accuracy: 0.908249331413\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('layer0_weights_0.npy', classifier.layers[0].weights.shares0)\n",
    "np.save('layer0_weights_1.npy', classifier.layers[0].weights.shares1)\n",
    "np.save('layer0_bias_0.npy', classifier.layers[0].bias.shares0)\n",
    "np.save('layer0_bias_1.npy', classifier.layers[0].bias.shares1)\n",
    "\n",
    "np.save('layer2_weights_0.npy', classifier.layers[2].weights.shares0)\n",
    "np.save('layer2_weights_1.npy', classifier.layers[2].weights.shares1)\n",
    "np.save('layer2_bias_0.npy', classifier.layers[2].bias.shares0)\n",
    "np.save('layer2_bias_1.npy', classifier.layers[2].bias.shares1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
